{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.11.8 torch-2.4.0.dev20240405+cu121 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=classify, mode=train, model=E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\classification//runs\\classify//train16\\weights//best.pt, data=../data/yolo_best, epochs=10, time=None, patience=100, batch=32, imgsz=256, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train17\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train... found 19325 images in 15 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\val... found 1018 images in 15 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   7375360  ultralytics.nn.modules.conv.Conv             [640, 1280, 3, 2]             \n",
      "  8                  -1  3  27865600  ultralytics.nn.modules.block.C2f             [1280, 1280, 3, True]         \n",
      "  9                  -1  1   1660175  ultralytics.nn.modules.head.Classify         [1280, 15]                    \n",
      "YOLOv8x-cls summary: 183 layers, 56161055 parameters, 56161055 gradients, 154.3 GFLOPs\n",
      "Transferred 302/302 items from pretrained weights\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs\\classify\\train17', view at http://localhost:6006/\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train... 19324 images, 1 corrupt: 100%|██████████| 19324/19324 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\15331800_14246331.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\15333519_14249267.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\43788517_53873850.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\43794535_54021735.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\43794654_53978890.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\10710748_7917928.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\11727763_9288038.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\11727968_9288065.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\25584803_28507520.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\25586947_28510344.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\16129339_20659799.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\19967524_20686711.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\47945410_59411875.jpg: ignoring corrupt image/label: Invalid image format GIF. Supported formats are:\n",
      "images: {'tiff', 'mpo', 'bmp', 'pfm', 'jpg', 'dng', 'png', 'tif', 'jpeg', 'webp'}\n",
      "videos: {'avi', 'mov', 'mpg', 'mp4', 'mkv', 'webm', 'wmv', 'mpeg', 'm4v', 'gif', 'ts', 'asf'}\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\27790832_31683479.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\27790856_31683576.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\27790947_31683839.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\27790970_31684115.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\27791631_31685690.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\27791818_31686258.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\19939332_20644774.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\19939332_20644775.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\32172201_37734672.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\32172217_37734693.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\32172224_37734701.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\38051443_45832431.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\38051499_45832562.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\10894623_8176853.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\10896439_8179473.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\19962543_20676732.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\24382523_26836634.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\24382524_26836635.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\5387378_1627264.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\11766808_9336463.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\11766808_9336464.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\11766846_9336515.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\30275178_35116925.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\30275178_35116926.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\10504721_7639990.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\10505370_7641139.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\10520815_7662184.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\10551757_7701311.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\10551769_7701446.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\31640137_37020937.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\41191422_50254354.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\8741453_5123979.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\8741453_5123994.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\\\8741453_5124180.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\, \\43817711_53915964.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\, \\43817720_53915976.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\, \\43817774_53916088.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\train\\, \\43817908_53916192.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\val... 1018 images, 0 corrupt: 100%|██████████| 1018/1018 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\val\\\\31687598.jpg: corrupt JPEG restored and saved\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING  E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_best\\val\\\\9336514.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added \n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns\\classify\\train17\u001B[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10       3.8G     0.2113         28        256: 100%|██████████| 604/604 [02:28<00:00,  4.07it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 16/16 [00:02<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.786      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.95G     0.5779         28        256: 100%|██████████| 604/604 [02:25<00:00,  4.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 16/16 [00:02<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.772      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      3.96G     0.6114         28        256: 100%|██████████| 604/604 [02:26<00:00,  4.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 16/16 [00:02<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.785      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.94G     0.5573         32        256:  20%|█▉        | 120/604 [00:29<01:59,  4.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m YOLO(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mMachineLearningProjects\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mml-practices\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124msrc\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mhaccaton\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mclassification//runs\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mclassify//train16\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mweights//best.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# load a pretrained model (recommended for training)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# model = YOLO('yolov8n-cls.yaml').load('yolov8n-cls.pt')  # build from YAML and transfer weights\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m results \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mtrain(data\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/yolo_best\u001B[39m\u001B[38;5;124m'\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, imgsz\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m, augment\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, batch\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m)\n",
      "File \u001B[1;32mE:\\AnacondaNew\\envs\\ml-course-spbu\\Lib\\site-packages\\ultralytics\\engine\\model.py:668\u001B[0m, in \u001B[0;36mModel.train\u001B[1;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[0;32m    665\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    667\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mhub_session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession  \u001B[38;5;66;03m# attach optional HUB session\u001B[39;00m\n\u001B[1;32m--> 668\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m    669\u001B[0m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[0;32m    670\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m}:\n",
      "File \u001B[1;32mE:\\AnacondaNew\\envs\\ml-course-spbu\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:198\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    195\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_train(world_size)\n",
      "File \u001B[1;32mE:\\AnacondaNew\\envs\\ml-course-spbu\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:400\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[1;34m(self, world_size)\u001B[0m\n\u001B[0;32m    398\u001B[0m losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;28;01mif\u001B[39;00m loss_len \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m}:\n\u001B[1;32m--> 400\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mset_description(\n\u001B[0;32m    401\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%11s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%11.4g\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m loss_len))\n\u001B[0;32m    402\u001B[0m         \u001B[38;5;241m%\u001B[39m (\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, mem, \u001B[38;5;241m*\u001B[39mlosses, batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcls\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    403\u001B[0m     )\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_callbacks(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mplots \u001B[38;5;129;01mand\u001B[39;00m ni \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplot_idx:\n",
      "File \u001B[1;32mE:\\AnacondaNew\\envs\\ml-course-spbu\\Lib\\site-packages\\tqdm\\std.py:1382\u001B[0m, in \u001B[0;36mtqdm.set_description\u001B[1;34m(self, desc, refresh)\u001B[0m\n\u001B[0;32m   1379\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ema_miniters \u001B[38;5;241m=\u001B[39m EMA(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msmoothing)\n\u001B[0;32m   1380\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefresh()\n\u001B[1;32m-> 1382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_description\u001B[39m(\u001B[38;5;28mself\u001B[39m, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, refresh\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1383\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;124;03m    Set/modify description of the progress bar.\u001B[39;00m\n\u001B[0;32m   1385\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1390\u001B[0m \u001B[38;5;124;03m        Forces refresh [default: True].\u001B[39;00m\n\u001B[0;32m   1391\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   1392\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdesc \u001B[38;5;241m=\u001B[39m desc \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m desc \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO('yolov8n-cls.yaml')  # build a new model from YAML\n",
    "model = YOLO('best.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='../data/yolo_best', epochs=10, imgsz=256, augment=True, batch=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T05:03:04.155243Z",
     "start_time": "2024-04-14T04:52:50.112791Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# \n",
    "# for img_dir in os.listdir(\"E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_val//test\"):\n",
    "#     for img in os.listdir(os.path.join(\"E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_val//test\", img_dir)):\n",
    "#         shutil.copy(os.path.join(\"E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_val//test\", img_dir, img), os.path.join(\"E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_val//train\", img_dir, img))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T20:40:05.350587Z",
     "start_time": "2024-04-13T20:39:55.740563Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for img_dir in os.listdir(\"E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_val//val\"):\n",
    "#     for img in os.listdir(os.path.join(\"E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_val//val\", img_dir))[::2]:\n",
    "#         shutil.move(os.path.join(\"E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_val//val\", img_dir, img), os.path.join(\"E:\\MachineLearningProjects\\ml-practices\\src\\haccaton\\data\\yolo_val//train\", img_dir, img))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T20:41:33.068628Z",
     "start_time": "2024-04-13T20:41:32.313939Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:31:56.194414Z",
     "start_time": "2024-04-13T09:31:55.986346Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOV8 model\n",
    "\n",
    "model = YOLO(r\"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 256x256  1.00,  0.00,  0.00,  0.00,  0.00, 22.8ms\n",
      "Speed: 12.2ms preprocess, 22.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "res = model([\"../data/plastinka.jpg\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T09:35:43.209969Z",
     "start_time": "2024-04-13T09:35:43.156649Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([4.9297e-06, 2.2324e-06, 6.2297e-04, 8.1473e-04, 1.3728e-05, 1.0827e-06, 1.0507e-05, 2.6825e-07, 4.1440e-05, 2.5264e-06, 9.9834e-01, 5.8498e-06, 1.3276e-05, 1.1464e-04, 1.4136e-05], device='cuda:0')]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.predict(source=\"../data/plastinka.jpg\", show=False, verbose=False)\n",
    "a = [r.probs.data for r in res]\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T09:45:10.380931Z",
     "start_time": "2024-04-13T09:45:10.276458Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Археология', 1: 'Графика', 2: 'ДПИ', 3: 'Документы', 4: 'Естественнонауч.коллекция', 5: 'Живопись', 6: 'Минералогия', 7: 'Нумизматика', 8: 'Оружие', 9: 'Печатная продукция', 10: 'Прочие', 11: 'Редкие книги', 12: 'Скульптура', 13: 'Техника', 14: 'Фото, негативы'}\n",
      "tensor([0.0665, 0.0179, 0.0755, 0.0659, 0.0292, 0.0112, 0.0539, 0.1632, 0.0223, 0.0949, 0.0704, 0.0629, 0.0634, 0.1360, 0.0669])\n",
      "{0: 'Археология', 1: 'Графика', 2: 'ДПИ', 3: 'Документы', 4: 'Естественнонауч.коллекция', 5: 'Живопись', 6: 'Минералогия', 7: 'Нумизматика', 8: 'Оружие', 9: 'Печатная продукция', 10: 'Прочие', 11: 'Редкие книги', 12: 'Скульптура', 13: 'Техника', 14: 'Фото, негативы'}\n",
      "tensor([0.0488, 0.0880, 0.0388, 0.0500, 0.0754, 0.0671, 0.0427, 0.0667, 0.0334, 0.1293, 0.0777, 0.0602, 0.0296, 0.0925, 0.0999])\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(res.names)\n",
    "    print(res.probs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Археология', 1: 'Графика', 2: 'ДПИ', 3: 'Документы', 4: 'Естественнонауч.коллекция', 5: 'Живопись', 6: 'Минералогия', 7: 'Нумизматика', 8: 'Оружие', 9: 'Печатная продукция', 10: 'Прочие', 11: 'Редкие книги', 12: 'Скульптура', 13: 'Техника', 14: 'Фото, негативы'}\n",
      "tensor([0.0647, 0.0994, 0.0529, 0.0462, 0.0627, 0.0385, 0.0805, 0.1372, 0.0559, 0.0344, 0.0371, 0.1002, 0.0911, 0.0376, 0.0617])\n",
      "{0: 'Археология', 1: 'Графика', 2: 'ДПИ', 3: 'Документы', 4: 'Естественнонауч.коллекция', 5: 'Живопись', 6: 'Минералогия', 7: 'Нумизматика', 8: 'Оружие', 9: 'Печатная продукция', 10: 'Прочие', 11: 'Редкие книги', 12: 'Скульптура', 13: 'Техника', 14: 'Фото, негативы'}\n",
      "tensor([0.0446, 0.0638, 0.0633, 0.0500, 0.0700, 0.0632, 0.0868, 0.1007, 0.0822, 0.1049, 0.0331, 0.0520, 0.0575, 0.0703, 0.0577])\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(res.names)\n",
    "    print(res.probs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
